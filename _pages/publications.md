---
layout: single
title: List of Publications
permalink: /publications/
author_profile: false
custom_css: pub
---

<div class="w3-container">

  <h2 class="w3-container w3-padding" style="font-weight: bold"> Early Drafts/Preprints</h2>
   <ul class="w3-ul">

   <li>
   <span class="title">Understanding the Population Structure Correction Regression</span>, <br>
   <span class="conf">(Preprint)</span>
   <span class="author">T. T. Mai, P. Alquier</span>
   [<a href="https://arxiv.org/abs/2102.05655" target="_blank">arXiv</a>]
   </li>

   <li>
   <span class="title">The Bayesian Learning Rule</span>, <br>
   <span class="conf">(Preprint)</span>
   <span class="author">M.E. Khan</span>, <span class="author"> H. Rue</span>
   [ <a href="https://arxiv.org/abs/2107.04562" target="_blank">arXiv</a> ]
   </li>


   <li>
   <span class="title">Beyond Target Networks: Improving Deep Q-learning with Functional Regularization</span>, <br>
   <span class="conf">(Preprint)</span>
   <span class="author">A. Piché, J. Marino, G. M. Marconi, C. Pal, M. E. Khan</span>
   [<a href="https://arxiv.org/abs/2106.02613" target="_blank">arXiv</a>]
   </li>

   <li>
   <span class="title"> Deviation inequalities for stochastic approximation by averaging</span>, <br>
   <span class="conf">(Preprint)</span>
   <span class="author">X. Fan, P. Alquier, P. Doukhan</span>
   [<a href="https://arxiv.org/abs/2102.08685" target="_blank">arXiv</a>]
   </li>

   <li>
   <span class="title"> Tight Risk Bound for High Dimensional Time Series Completion</span>, <br>
   <span class="conf">(Preprint)</span>
   <span class="author">P. Alquier, N. Marie, A. Rosier</span>
   [<a href="https://arxiv.org/abs/2102.08178" target="_blank">arXiv</a>]
   </li>

  <li>
       <span class="title">Universal Robust Regression via Maximum Mean Discrepancy</span>, <br>
       <span class="conf">(Preprint)</span>
       <span class="author">P. Alquier, M. Gerber</span>
       [<a href="https://arxiv.org/abs/2006.00840" target="_blank">arXiv</a>]
  </li>

     <li>
       <span class="title"> Estimation of Copulas via Maximum Mean Discrepancy</span>, <br>
       <span class="conf">(<a href="https://www.tandfonline.com/journals/uasa20" target="_blank">JASA</a>)</span>
       <span class="author">P. Alquier, B.-E. Chérief-Abdellatif, A. Derumigny, J.-D. Fermanian</span>
       [<a href="https://doi.org/10.1080/01621459.2021.2024836" target="_blank">Journal version (to appear)</a>]
       [<a href="https://arxiv.org/abs/2010.00408" target="_blank">arXiv</a>]
  </li>

   </ul>

  <h2 class="w3-container w3-padding">2022</h2>
   <ul class="w3-ul">

  <li>
       <span class="title">Finite sample properties of parametric MMD estimation: robustness to misspecification and dependence</span>, <br>
       <span class="conf">(<a href="http://www.bernoulli-society.org/index.php/publications/bernoulli-journal/bernoulli-journal" target="_blank">Bernoulli</a>)</span>
       <span class="author">B.E. Chérief-Abdellatif, P. Alquier</span>
       [<a href="https://doi.org/10.3150/21-BEJ1338" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/abs/1912.05737" target="_blank">arXiv</a>] 
  </li>

   </ul>

  <h2 class="w3-container w3-padding">2021</h2>
   <ul class="w3-ul">

      <li>
         <span class="title">Knowledge-Adaptation Priors</span>, <br>
         <span class="conf">(<a href="https://papers.nips.cc/paper/2021/">NeurIPS 2021</a>)</span>
         <span
         class="author">M.E. Khan, S. Swaroop</span>    
         [ <a href="http://arxiv.org/abs/2106.08769" target="_blank">arXiv</a> ] [ <a href="papers/July23_2021_CL_workshop.pdf" target="_blank">Slides</a> ] [ <a href="https://t.co/v68OrIE0Xz?amp=1" target="_blank">Tweet</a> ] [ <a href="https://t.co/XBRwRh3Lde?amp=1" target="_blank">SlidesLive Video</a> ]
		 </li>

      <li>
         <span class="title">Dual Parameterization of Sparse Variational Gaussian Processes</span>, <br>
         <span class="conf">(<a href="https://papers.nips.cc/paper/2021/">NeurIPS 2021</a>)</span>
         <span class="author">P. Chang, V. Adam, M.E. Khan, A. Solin</span>    
      </li>


   <li>
   <span class="title">  Meta-strategy for Learning Tuning Parameters with Guarantees</span>, <br>
   <span class="conf">(<a href="https://www.mdpi.com/journal/entropy" target="_blank">Entropy</a>)</span>
   <span class="author">D. Meunier, P. Alquier</span>
   [<a href="https://doi.org/10.3390/e23101257" target="_blank">Published version</a>]
   [<a href="https://arxiv.org/abs/2102.02504" target="_blank">arXiv</a>]
   </li>

   <li>
         <span class="title">Subset-of-Data Variational Inference for Deep Gaussian-Process Regression</span>, <br>
         <span class="conf">(<a href="https://auai.org/uai2021/accepted_papers" target="_blank">UAI 2021</a>)</span>
         <span class="author"> A. Jain, P.K. Srijith, </span><span class="author">M.E. Khan</span>,   
          [ <a href="https://arxiv.org/abs/2107.08265" target="_blank">arXiv</a> ]
   </li>

   <li>
     <span class="title">Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning</span>, <br>
       <span class="conf">(<a href="http://proceedings.mlr.press/v139/" target="_blank">ICML 2021</a>)</span>
     <span class="author">A. Immer, M. Bauer, V. Fortuin, G. Rätsch, M. E. Khan</span>
       [<a href="http://proceedings.mlr.press/v139/immer21a.html" target="_blank">Published version</a>]
     [<a href="https://arxiv.org/abs/2104.04975" target="_blank">arXiv</a>]
   </li>
   
     <li>
       <span class="title"> Tractable structured natural gradient descent using local parameterizations</span>, <br>
       <span class="conf">(<a href="http://proceedings.mlr.press/v139/" target="_blank">ICML 2021</a>)</span>
       <span class="author">W. Lin, F. Nielsen, M. E. Khan, M. Schmidt</span>
       [<a href="http://proceedings.mlr.press/v139/lin21e.html" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/abs/2102.07405" target="_blank">arXiv</a>]
  </li>

     <li>
       <span class="title">Non-exponentially weighted aggregation: regret bounds for unbounded loss functions</span>, <br>
       <span class="conf">(<a href="http://proceedings.mlr.press/v139/" target="_blank">ICML 2021</a>)</span>
       <span class="author">P. Alquier</span>
       [<a href="http://proceedings.mlr.press/v139/alquier21a.html" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/abs/2009.03017" target="_blank">arXiv</a>]
  </li>

    <li>
       <span class="title"> Improving predictions of Bayesian neural networks via local linearization</span>, <br>
       <span class="conf">(<a href="http://proceedings.mlr.press/v130/" target="_blank">AISTATS 2021</a>)</span>
       <span class="author"> A. Immer, M. Korzepa, M. Bauer </span>
       [<a href="https://proceedings.mlr.press/v130/immer21a.html" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/pdf/2008.08400" target="_blank">arXiv</a>]
  </li>

     <li>
       <span class="title"> A Theoretical Analysis of Catastrophic Forgetting through the NTK Overlap Matrix</span>, <br>
       <span class="conf">(<a href="http://proceedings.mlr.press/v130/" target="_blank">AISTATS 2021</a>)</span>
       <span class="author">T. Doan, M. Abbana Bennani, B. Mazoure, G. Rabusseau, P. Alquier</span>
       [<a href="https://proceedings.mlr.press/v130/doan21a.html" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/abs/2010.04003" target="_blank">arXiv</a>]
  </li>

  <li>
       <span class="title">Simultaneous dimension reduction and clustering via the NMF-EM algorithm</span>, <br>
       <span class="conf">(<a href="https://www.springer.com/journal/11634" target="_blank">Advances in Data Analysis and Classification</a>)</span>
       <span class="author">L. Carel, P. Alquier</span>
       [<a href="https://doi.org/10.1007/s11634-020-00398-4" target="_blank">Published version</a>]
       [<a href="https://arxiv.org/abs/1709.03346" target="_blank">arXiv</a>]
  </li>

   </ul>

  <h2 class="w3-container w3-padding">2020</h2>
   <ul class="w3-ul">
      <li>
         <span class="title">Continual Deep Learning by Functional Regularisation of Memorable Past</span><br>
         <span class="conf">(<a href="https://papers.nips.cc/paper/2020/" target="_blank">NeurIPS 2020</a>)</span>
         <span class="author">P. Pan<sup>*</sup>, S. Swaroop<sup>*</sup>, A. Immer, R. Eschenhagen, R. E. Turner, M.E. Khan</span>
         [<a href="https://papers.nips.cc/paper/2020/hash/2f3bbb9730639e9ea48f309d9a79ff01-Abstract.html" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/2004.14070" target="_blank">ArXiv</a>]
         [<a href="https://github.com/team-approx-bayes/fromp" target="_blank">Code</a>]
         [<a href="FROMP_NeurIPS2020_poster.pdf" target="_blank">Poster</a>]<br>
         <b>Oral presentation</b>, 1% of all submissions (105 out of 9454 submissions).<br>
      </li>

      <li>
         <span class="title">Approximate Bayesian Inference</span>, <br>
         <span class="conf">(<a href="https://www.mdpi.com/journal/entropy" target="_blank">Entropy</a>)</span>
         <span class="author">P. Alquier</span>
         [<a href="https://doi.org/10.3390/e22111272" target="_blank">Paper</a>]
      </li>

      <li>
         <span class="title">Concentration of tempered posteriors and of their variational approximations</span>, <br>
         <span class="conf">(<a href="https://imstat.org/journals-and-publications/annals-of-statistics/" target="_blank">Annals of Statistics</a>)</span>
         <span class="author">P. Alquier, J. Ridgway</span>
         [<a href="https://dx.doi.org/doi:10.1214/19-AOS1855" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/1706.09293" target="_blank">arXiv</a>]
      </li>

      <li>
         <span class="title">Fast Variational Learning in State-Space Gaussian Process Models</span>, <br>
         <span class="conf">(<a href="https://ieeemlsp.cc/" target="_blank">MLSP 2020</a>)</span>
         <span class="author">P. E. Chang, W. J. Wilkinson, </span><span class="author">M.E. Khan, A. Solin</span>
         [<a href="https://doi.org/10.1109/MLSP49062.2020.9231560" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/2007.04731" target="_blank">arXiv</a>]
      </li>

      <li>
         <span class="title">High-dimensional VAR with low-rank transition</span>, <br>
         <span class="conf">(<a href="https://link.springer.com/journal/11222/volumes-and-issues/30-4" target="_blank">Statistics and Computing</a>)</span>
         <span class="author">P. Alquier, K. Bertin, P. Doukhan, R. Garnier</span>   
         [<a href="https://doi.org/10.1007/s11222-020-09929-7" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/1905.00959" target="_blank">arXiv</a>]
      </li>

      <li>
         <span class="title">AI for Social Good: Unlocking the Opportunity for Positive Impact</span>, <br>
         <span class="conf">(<a href="https://www.nature.com/ncomms/" target="_blank">Nature Communications</a> 2020)</span>
         <span class="author"> with Nenad Tomašev and many others </span> <br>
         <!--<span class="author"> Nenad Tomašev, Julien Cornebise, Frank Hutter, Shakir Mohamed, Angela Picciariello, Bec Connelly, Danielle Belgrave, Daphne Ezer, Fanny Cachat van der Haert, Frank Mugisha, Gerald Abila, Hiromi Arai, Hisham Almiraat, Julia Proskurnia, Kyle Snyder, Mihoko Otake-Matsuura, Mustafa Othman, Tobias Glasmachers, Wilfried de Wever, Yee Whye Teh, Mohammad Emtiyaz Khan, Ruben De Winne, Tom Schaul, and Claudia Clopath </span> -->    
         [<a href="https://doi.org/10.1038/s41467-020-15871-z" target="_blank">Paper</a>]
         [<a href="https://t.co/Lg6qXxNIBg?amp=1" target="_blank">Declaration on AI2SG</a>]
         [<a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19082" target="_blank">Dagstuhl AI4SG 2019</a>]
         [<a href="https://www.dagstuhl.de/no_cache/en/about-dagstuhl/news/detail/meldung/720/" target="_blank">Press Release</a>]
      </li>
      <li>
         <span class="title">Training Binary Neural Networks using the Bayesian Learning Rule</span>, <br>
         <span class="conf">(<a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial" target="_blank">ICML 2020</a>)</span>
         <span class="author"> X. Meng, R. Bachmann, M.E. Khan</span>
	 [<a href="http://proceedings.mlr.press/v119/meng20a.html" target="_blank">Published version</a>] 
         [<a href="https://arxiv.org/abs/2002.10778" target="_blank">arXiv</a>] [<a href="https://github.com/team-approx-bayes/BayesBiNN" target="_blank&quot;">Code</a>]
      </li>

      <li>
         <span class="title">Handling the Positive-Definite Constraint in the Bayesian Learning Rule</span>, <br>
         <span class="conf">(<a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial" target="_blank">ICML 2020</a>)</span>
         <span class="author"> W. Lin, M. Schmidt, M.E. Khan</span>
	 [<a href="http://proceedings.mlr.press/v119/lin20d.html" target="_blank">Published version</a>] 
         [<a href="https://arxiv.org/abs/2002.10060" target="_blank">arXiv</a>]
      </li>
      <li>
         <span class="title">VILD: Variational Imitation Learning with Diverse-quality Demonstrations</span>, <br>
         <span class="conf">(<a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial" target="_blank">ICML 2020</a>)</span>
         <span class="author"> V. Tangkaratt, B. Han, M.E. Khan,</span><span class="author"> M. Sugiyama</span>
	 [<a href="http://proceedings.mlr.press/v119/tangkaratt20a.html" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/1909.06769" target="_blank">arXiv</a>]
      </li>

      <li>
         <span class="title">MMD-Bayes: Bayesian Estimation via Maximum Mean Discrepancy</span>, <br>
         <span class="conf">(<a href="http://proceedings.mlr.press/v118/" target="_blank">AABI 2019</a>)</span>
         <span class="author">B.E. Chérief-Abdellatif, P. Alquier</span>
         [<a href="http://proceedings.mlr.press/v118/cherief-abdellatif20a.html" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/1909.13339" target="_blank">arXiv</a>]
      </li>

      <li>
        <span class="title">Exact Recovery of Low-rank Tensor Decomposition under Reshuffling</span>, <br>
        <span class="conf">(<a href="https://aaai.org/Conferences/AAAI-20/" target="_blank">AAAI 2020</a>)</span>
        <span class="author">C. Li, M.E. Khan</span>, <span class="author"> Z. Sun, G. Niu, B. Han, S. Xie, Q. Zhao</span>   
        [<a href="https://arxiv.org/abs/1805.08465" target="_blank">arXiv</a>]
      </li>


   </ul>

  <h2 class="w3-container w3-padding">2019</h2>
   <ul class="w3-ul">

      <li>
      <span class="title">Practical Deep Learning with Bayesian Principles</span>, <br>
      <span class="conf">(<a href="https://nips.cc/Conferences/2019" target="_blank">NeurIPS 2019</a>)</span> <span class="author">K. Osawa, S. Swaroop, A. Jain, R. Eschenhagen, R.E. Turner, R. Yokota, M.E. Khan</span>.
      [<a href="https://proceedings.neurips.cc/paper/2019/hash/b53477c2821c1bf0da5d40e57b870d35-Abstract.html" target="_blank">Published version</a>]
      [<a href="https://arxiv.org/abs/1906.02506" target="_blank">arXiv</a>] [<a href="https://github.com/team-approx-bayes/dl-with-bayes" target="_blank&quot;">Code</a>]
      </li>

      <li>
      <span class="title">Approximate Inference Turns Deep Networks into Gaussian Processes</span>, <br>
      <span class="conf">(<a href="https://nips.cc/Conferences/2019" target="_blank">NeurIPS 2019</a>)</span> <span class="author">M.E. Khan, A. Immer, E. Abedi, M. korzepa</span>.
      [<a href="https://proceedings.neurips.cc/paper/2019/hash/b3bbccd6c008e727785cb81b1aa08ac5-Abstract.html" target="_blank">Published version</a>]
      [<a href="https://arxiv.org/abs/1906.01930" target="_blank">arXiv</a>] [<a href="https://github.com/team-approx-bayes/dnn2gp" target="_blank&quot;">Code</a>]
      </li>

      <li>
         <span class="title">A Generalization Bound for Online Variational Inference</span> (<a href="http://www.acml-conf.org/2019/conference/awards/" target="_blank"><b>best paper award</b></a>),<br>
         <span class="conf">(<a href="http://www.acml-conf.org/2019/" target="_blank">ACML 2019</a>)</span> <span class="author"> B.-E. Chérief-Abdellatif, P. Alquier, M.E. Khan</span>.
      [<a href="http://proceedings.mlr.press/v101/cherief-abdellatif19a.html" target="_blank">Published version</a>]
      [<a href="https://arxiv.org/abs/1904.03920" target="_blank">arXiv</a>]
      </li>

      <li>
         <span class="title">Matrix factorization for multivariate time series analysis</span>, <br>
         <span class="conf">(<a href="https://imstat.org/journals-and-publications/electronic-journal-of-statistics/" target="_blank">EJS</a>)</span>
         <span class="author">P. Alquier, N. Marie</span>
	 [<a href="http://doi.org/doi:10.1214/19-EJS1630" target="_blank">Published version</a>]
         [<a href="https://arxiv.org/abs/1903.05589" target="_blank">arXiv</a>]
      </li>

      <li>
      <span class="title">Fast and Simple Natural-Gradient Variational Inference with Mixture of Exponential-family Approximations</span>, <br>
      <span class="conf">(<a href="https://icml.cc/" target="_blank">ICML, 2019</a>)</span> <span class="author">W. Lin, </span> <span class="author">M.E. Khan, M. Schmidt</span>.
      [<a href="https://arxiv.org/abs/1906.02914" target="_blank">arXiv</a>] [<a href="http://proceedings.mlr.press/v97/lin19b.html" target="_blank">Published version</a>][<a href="https://github.com/yorkerlin/VB-MixEF" target="_blank&quot;">Code</a>]<br>
      Also appeared at the <span class="conf"><a href="http://approximateinference.org/" target="_blank">Symposium on Advances in Approximate Bayesian Inference at NeurIPS 2018</a></span>
      [<a href="papers/mixExp.pdf" target="_blank">Short Paper</a>] <br>
      </li>

      <li>
      <span class="title">Stein's Lemma for the Reparameterization Trick with Exponential Family Mixtures</span>, <br>
      <span class="conf">(<a href="https://steinworkshop.github.io/" target="_blank">ICML workshop on Stein's Method in ML and Stats</a>, 2019)</span> <span class="author">W. Lin, </span> <span class="author">M.E. Khan, M. Schmidt</span>.
      [<a href="https://arxiv.org/abs/1910.13398" target="_blank">arXiv</a>]
      </li>

      <li>
      <span class="title">Scalable Training of Inference Networks for Gaussian-Process Models</span>, <br>
      <span class="conf">(<a href="https://icml.cc/" target="_blank">ICML, 2019</a>)</span> <span class="author">J. Shi,</span> <span class="author">M.E. Khan, J. Zhu</span>.
      [<a href="https://arxiv.org/abs/1905.10969" target="_blank">arXiv</a>] [<a href="http://proceedings.mlr.press/v97/shi19a.html" target="_blank"> Published version</a>][<a href="https://github.com/thjashin/gp-infer-net" target="_blank&quot;">Code</a>]
      </li>

      <li>
      <span class="title">TD-Regularized Actor-Critic Methods</span>, <br>
      <span class="conf">(<a href="https://www.springer.com/journal/10994" target="_blank">Machine Learning</a><a>, 2019. A short version appeared at </a><a href="https://ewrl.wordpress.com/ewrl14-2018/" target="_blank">EWRL 2018</a>)</span> <br>
      <span class="author">S. Parisi, V. Tangkaratt, J. Peters, M.E. Khan</span>.
      [<a href="https://doi.org/10.1007/s10994-019-05788-0" target="_blank"> Published version</a>] [<a href="https://arxiv.org/abs/1812.08288" target="_blank">arXiv</a>] [<a href="https://ewrl.files.wordpress.com/2018/09/ewrl_14_2018_paper_52.pdf" target="_blank&quot;">Short version at EWRL 2018</a>]
      </li>

   </ul>
  <h2 class="w3-container w3-padding">2018</h2>
   <ul class="w3-ul">

      <li>
      <span class="title">SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient</span>, <br>
      <span class="conf">(<a href="https://nips.cc/Conferences/2018/Schedule?showEvent=11605" target="_blank">NeurIPS 2018</a>)</span>
      <span class="author">A. Miskin, F. Kunstner, D. Nielsen, M. Schmidt, M.E. Khan</span>.
 	 [<a href="https://proceedings.neurips.cc/paper/2018/hash/d3157f2f0212a80a5d042c127522a2d5-Abstract.html" target="_blank"> Published version</a>]
         [<a href="http://arxiv.org/abs/1811.04504" target="_blank">arXiv</a>]
         [<a href="https://github.com/aaronpmishkin/SLANG/blob/master/poster/SLANG_NIPS_2018_Poster.pdf" target="_blank">Poster</a>]
         [<a href="https://www.youtube.com/watch?v=ekaB_weR5Bw&amp;feature=youtu.be" target="_blank">3-min Video</a>]
         [<a href="https://github.com/aaronpmishkin/SLANG" target="_blank">Code</a>]
      </li>

      <!--<li>
      <span class="title">Fast and Simple Natural-Gradient Variational Inference with Mixture of Exponential-family Approximations</span>, <br>
      <span class="conf">(<a href="http://approximateinference.org/" target="_blank">Symposium on Advances in Approximate Bayesian Inference at NeurIPS 2018</a>)</span><br>
      <span class="author">W. Lin, M. Schmidt, M.E. Khan</span>.
      [<a href="papers/mixExp.pdf" target="_blank"> Paper </a>].
      </li>-->

      <li>
      <span class="title">Natural Variational Continual Learning</span>, <br>
      <span class="conf">(<a href="https://sites.google.com/view/continual2018" target="_blank">Continual Learning Workshop at NIPS 2018</a>)</span><br>
      <span class="author">H. Tseran,</span> <span class="author">M.E. Khan, T. Harada, T. Bui</span>
      [<a href="papers/nvcl.pdf" target="_blank">Paper</a>].
      </li>

      <li>  
      <span class="title">Fast yet Simple Natural-Gradient Descent for Variational Inference in Complex Models</span>, <br>
    <span class="conf">(<a href="http://www.isita.ieice.org/2018/home.html" target="_blank">ISITA 2018</a>)</span>
         <span class="author">M.E. Khan and D. Nielsen</span>,   
         [<a href="https://arxiv.org/abs/1807.04489" target="_blank">arXiv</a>] [<a href="https://doi.org/10.23919/ISITA.2018.8664326" target="_blank">IEEE explore</a>]  [<a href="papers/isita2018_slides.pdf" target="_blank">Slides</a>]
      </li>

      <li>  
      <span class="title">Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam</span>, <br>
    <span class="conf">(<a href="https://icml.cc/" target="_blank">ICML 2018</a>)</span>
         <span class="author">M.E. Khan, D. Nielsen, V. Tangkaratt, W. Lin, Y. Gal, and A. Srivastava</span>,   
         [<a href="http://proceedings.mlr.press/v80/khan18a.html" target="_blank"> Published version</a>]
         [<a href="https://arxiv.org/abs/1806.04854" target="_blank">arXiv</a>]
         [<a href="https://github.com/emtiyaz/vadam/" target="_blank">Code</a>]
         [<a href="papers/icml2018_slides.pdf" target="_blank">Slides</a>]
      </li>

      <li>  
      <span class="title">Variational Message Passing with Structured Inference Networks</span>, <br>
    <span class="conf">(<a href="https://iclr.cc/" target="_blank">ICLR 2018</a>)</span>
         <span class="author"> W. Lin, N. Hubacher, and M.E. Khan</span>,
         [<a href="https://openreview.net/forum?id=HyH9lbZAW" target="_blank">Paper</a>]
         [<a href="http://arxiv.org/abs/1803.05589" target="_blank">arXiv Version</a>]
         [<a href="https://github.com/emtiyaz/vmp-for-svae/" target="_blank">Code</a>]
      </li>
     <li>  
      <span class="title">Bayesian Nonparametric Poisson-Process Allocation for Time-Sequence Modeling</span>, <br>
    <span class="conf">(<a href="http://www.aistats.org/" target="_blank">AI-Stats 2018</a>)</span>
    <span class="author"> H. Ding, M.E. Khan</span>, <span class="author">I. sato, M. Sugiyama</span>,
[<a href="http://proceedings.mlr.press/v84/ding18a.html" target="_blank">Published version</a>]
[<a href="https://github.com/Dinghy/BaNPPA" target="_blank">Code</a>]
      </li>

   </ul>
</div>


<div class="w3-container">
  <h2 class="w3-container w3-padding">2017</h2>
   <ul class="w3-ul">
   <li>
	 <span class="title">Vprop: Variational Inference using RMSprop</span>, <br>
    <span class="conf">(<a href="http://approximateinference.org/" target="_blank">NIPS 2017, Workshop on Bayesian Deep Learning</a>)</span><br>
         <span class="author">M.E. Khan, Z. Liu, V. Tangkaratt, and Y. Gal</span>
[<a href="https://arxiv.org/abs/1712.01038" target="_blank">Workshop version</a>]
[<a href="papers/vprop_poster.pdf" target="_blank">Poster</a>]
    </li>

   <li>
	 <span class="title">Variational Adaptive-Newton Method for Explorative-Learning</span>, <br>
    <span class="conf">(<a href="http://approximateinference.org/" target="_blank">NIPS 2017, Workshop on Advances in Approximate Bayesian Inference</a>)</span><br>
         <span class="author">M.E. Khan, W. Lin, V. Tangkaratt, Z. Liu, and D. Nielsen</span>
[<a href="http://arxiv.org/abs/1711.05560" target="_blank">arXiv Version</a>]
   [<a href="papers/van_poster.pdf" target="_blank">Poster</a>]
    </li>

   <li>
	 <span class="title">Natural-Gradient Stochastic Variational Inference for Non-Conjugate Structured Variational Autoencoder</span>, <br>
         <span class="conf">(<a href="https://deepstruct.github.io/ICML17" target="_blank">ICML 2017, Workshop on Deep Structure Prediction</a>)</span>
         <span class="author">W. Lin, M.E. Khan</span>, <span class="author">N. Hubacher, and D. Nielsen</span>
[<a href="papers/1stDeepStructWS_paper_10.pdf" target="_blank">Paper</a>]
    </li>

    <li id="#aistats2017">
			<span class="title">Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models</span>, <br>
         <span class="conf">(<a href="http://www.aistats.org/" target="_blank">AIstats 2017</a>)</span>
         <span class="author">M.E. Khan and W. Lin</span>
[<a href="http://proceedings.mlr.press/v54/khan17a.html" target="_blank"> Published version </a>]
[<a href="https://arxiv.org/abs/1703.04265" target="_blank">arXiv </a>]
[<a href="https://github.com/emtiyaz/cvi/" target="_blank">Code for Logistic Reg + GPs</a>]
[<a href="https://github.com/emtiyaz/cvi/" target="_blank">Code for Correlated Topic Model</a>]
    </li>

    <li>
			<span class="title">SmarPer: Context-Aware and Automatic Runtime-Permissions for Mobile Devices</span>, <br>
         <span class="conf">(<a href="https://www.ieee-security.org/TC/SP2017/" target="_blank">38th IEEE Symposium on Security and Privacy (S&amp;P;)</a>, San Jose, CA, USA, May 22-24, 2017)</span><br>
			<span class="author">K. Olejnik, I. I. Dacosta Petrocelli, J. C. Soares Machado, K. Huguenin, M.E. Khan</span> <span class="author">, and J.-P. Hubaux</span>
[<a href="https://doi.org/10.1109/SP.2017.25" target="_blank">Published paper</a>]
[<a href="https://github.com/lca1/smarper" target="_blank">Code</a>]
[<a href="https://spism.epfl.ch/smarper/" target="_blank">SmarPer Homepage</a>]
		</li>

    <li id="#bs2017">
			<span class="title">Gaussian-Process-Based Emulators for Building Performance Simulation</span>, <br>
         <span class="conf">(<a href="http://www.buildingsimulation2017.org/" target="_blank">Building Simulation 2017</a>)</span>
			<span class="author">P. Rastogi, M.E. Khan</span> <span class="author">and M. Anderson</span>
[<a href="papers/Building_Simulation.pdf" target="_blank">Paper</a>]
[<a href="https://zenodo.org/record/291858#.WME-XBKGNo4" target="_blank">Building Simulation Data</a>]
[<a href="https://github.com/paragrastogi/GPregressionInBS" target="_blank">Code</a>]
		</li>

</ul></div>
  <br>

<div style="pointer-events: none !important; display: none !important; position: absolute; top: 0px !important; left: 0px !important; z-index: 2147483647 !important; box-sizing: content-box !important;"></div>
