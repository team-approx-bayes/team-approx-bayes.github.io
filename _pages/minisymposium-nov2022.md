---
layout: single
title: Machine-Learning Seminar
permalink: /minisymposium/
author_profile: false
---
November 1st, 2022 at [RIKEN Center for AI Project, Tokyo](https://aip.riken.jp)

## Information
- This seminar includes a total of 7 talks from external visitors and
people from AIP
- Each talk is 40 minutes, with 10 minutes questions and discussion
  afterwards. All talks will be held in the open area at
  [RIKEN AIP](https://aip.riken.jp/access/)
- The event is open to the public, but in case too many people join, AIP people are given priority. Register [here]().

## Program
- 09:30 -- 09:55 Registration and setting up.
- **Session I** (Chair: [Gian Maria Marconi](https://gmmarconi.github.io))
  - 10:00 -- 10:50 [JinYeong Bak](https://nosyu.kr), *Title tba*,
    [abstract](#1)
  - 10:50 -- 11:40 [Thomas Möllenhoff](https://thomasmoellenhoff.net),
    *SAM as an Optimal Relaxation of Bayes*, [abstract](#2)
  - 11:40 -- 12:30 [Alexander Immer](https://aleximmer.github.io),
  *Title tba*, [abstract](#3)
- 12:30 -- 14:00 Lunch break
- **Session II** (Chair: [Thomas Möllenhoff](https://thomasmoellenhoff.net))
  - 14:00 -- 14:50 [Mehmet Eren Kiral](https://ekiral.github.io),
    *title tba*, [abstract](#4)
  - 14:50 -- 15:40
    [Konstantinos Pitas](https://www.konstantinos-pitas.com), *title tba*, [abstract](#5)
- 15:40 -- 16:00 Coffee break
- **Session III** (Chair: [Jooyeon Kim](https://scholar.google.com/citations?user=ie5WNHcAAAAJ))
  - 16:00 -- 16:50
    [Carlo D'Eramo](https://www.ias.informatik.tu-darmstadt.de/Team/CarloDEramo),
    *title tba*, [abstract](#6) 
  - 16:50 -- 17:40
    [Georgia Chalvatzaki](https://www.ias.informatik.tu-darmstadt.de/Team/GeorgiaChalvatzaki),
        *title tba*, [abstract](#7)
- 18:00 Concluding remarks

## Title and Abstracts
<a name="1"></a>
### [JinYeong Bak](https://nosyu.kr), Sung Kyun Kwan University
Title: *tba*

Abstract: *tba*

<a name="2"></a>
### [Thomas Möllenhoff](https://thomasmoellenhoff.net), RIKEN AIP
Title: SAM as an Optimal Relaxation of Bayes

Abstract: Sharpness-aware minimization (SAM) and related adversarial deep-learning methods can drastically improve generalization, but their underlying mechanisms are not yet fully understood. Here, we establish SAM as a relaxation of the Bayes objective where the expected negative-loss is replaced by the optimal convex lower bound, obtained by using the so-called Fenchel biconjugate. The connection enables a new Adam-like extension of SAM to automatically obtain reasonable uncertainty estimates, while sometimes also improving its accuracy. By connecting adversarial and Bayesian methods, our work opens a new path to robustness.

<a name="3"></a>
###  [Alexander Immer](https://aleximmer.github.io), ETH Center for Learning Systems 
Title: *tba*

Abstract: *tba*

<a name="4"></a>
### [Mehmet Eren Kiral](https://ekiral.github.io), RIKEN AIP
Title: *tba*

Abstract: *tba*


<a name="5"></a>
###  [Konstantinos Pitas](https://www.konstantinos-pitas.com), INRIA Grenoble
Title: *tba*

Abstract: *tba*


<a name="6"></a>
### [Carlo D'Eramo](https://www.ias.informatik.tu-darmstadt.de/Team/CarloDEramo), TU Darmstadt
Title: *tba*

Abstract: *tba*


<a name="7"></a>
### [Georgia Chalvatzaki](https://www.ias.informatik.tu-darmstadt.de/Team/GeorgiaChalvatzaki), TU Darmstadt
Title: *tba*

Abstract: *tba*

